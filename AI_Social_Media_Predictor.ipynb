{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c31eef0b-210f-4a3d-b19f-96f30de7f568",
   "metadata": {},
   "source": [
    "# AI-Based Social Media Post & Reel Performance Predictor\n",
    "## Using Multimodal Machine Learning (Text + Image + Video + Audio)\n",
    "\n",
    "This project predicts Instagram post/reel performance (High/Medium/Low) using multimodal features. Adapted to your dataset: image_path, caption, hashtags, likes.\n",
    "\n",
    "**Platform**: Instagram\n",
    "**Dashboard**: Streamlit (code provided at the end)\n",
    "**Dataset**: `Projects/Untitled Folder/instagram_dataset.csv` (columns: image_path, caption, hashtags, likes)\n",
    "\n",
    "Install dependencies: `pip install torch torchvision transformers scikit-learn pandas numpy opencv-python librosa streamlit pillow requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c03ccf4-b803-4717-aef3-3a106c01d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sid\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "385b2f6a-3039-47d2-a506-d0dd9a0ed738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\sid\\anaconda3\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\sid\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from opencv-python) (2.1.3)\n",
      "Requirement already satisfied: librosa in c:\\users\\sid\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in c:\\users\\sid\\anaconda3\\lib\\site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sid\\anaconda3\\lib\\site-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sid\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\sid\\anaconda3\\lib\\site-packages (from standard-aifc->librosa) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\sid\\anaconda3\\lib\\site-packages (from standard-aifc->librosa) (0.2.2)\n",
      "Requirement already satisfied: torch in c:\\users\\sid\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sid\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sid\\anaconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\sid\\anaconda3\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sid\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sid\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n",
    "!pip install opencv-python\n",
    "!pip install librosa\n",
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b40101e9-c35c-4e69-acb7-1cbfd2452201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, CLIPProcessor, CLIPModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235d6f6-44c5-43e4-93b9-3dfbe0a187c5",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore Dataset\n",
    "Load your dataset with columns: image_path, caption, hashtags, likes. Supplement with open datasets if needed.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff6abd5d-cc3c-46f2-8b71-e146f2fb430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   image_path                caption                           hashtags  \\\n",
      "0   1  image_1.jpg  Small moments matter.    #goodday #motivation #lifestyle   \n",
      "1   2  image_2.jpg      Adventure awaits.  #travelgram #vacation #wanderlust   \n",
      "2   3  image_3.jpg   Latest product drop!        #reviews #brand #onlineshop   \n",
      "3   4  image_4.jpg        Must-have item!  #onlineshop #newproduct #shopping   \n",
      "4   5  image_5.jpg  Sweat. Smile. Repeat.   #healthyliving #fitlife #workout   \n",
      "\n",
      "   likes  \n",
      "0   4442  \n",
      "1   3551  \n",
      "2   1700  \n",
      "3   1758  \n",
      "4   1479  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          500 non-null    int64 \n",
      " 1   image_path  500 non-null    object\n",
      " 2   caption     500 non-null    object\n",
      " 3   hashtags    500 non-null    object\n",
      " 4   likes       500 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 19.7+ KB\n",
      "None\n",
      "Likes summary: count     500.000000\n",
      "mean     2602.800000\n",
      "std      1387.573225\n",
      "min        61.000000\n",
      "25%      1515.000000\n",
      "50%      2559.000000\n",
      "75%      3827.500000\n",
      "max      4996.000000\n",
      "Name: likes, dtype: float64\n",
      "Performance counts: performance\n",
      "High          465\n",
      "Low/Medium     35\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('instagram_dataset.csv')\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "# Compute engagement score (using only likes, as per your data)\n",
    "df['engagement'] = df['likes']\n",
    "\n",
    "# Categorize performance based on likes\n",
    "thresholds = df['likes'].quantile([0.25, 0.75])\n",
    "\n",
    "# Example: Based on your data (adjust numbers from df['likes'].describe())\n",
    "# Low: < 50 likes, Medium: 50-200, High: >200 (make bins narrower)\n",
    "df['performance'] = pd.cut(df['likes'], bins=[-np.inf, 500, np.inf], labels=['Low/Medium', 'High'])  # Combine Low and Medium\n",
    "\n",
    "\n",
    "# Add this to check your data\n",
    "print(\"Likes summary:\", df['likes'].describe())  # Shows min, max, average likes\n",
    "print(\"Performance counts:\", df['performance'].value_counts())  # Shows how many High/Medium/Low\n",
    "\n",
    "# Note: No reels in this dataset; assuming all are posts (images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41261b-9c52-459e-a33b-503cf54e234e",
   "metadata": {},
   "source": [
    "## Step 2: Feature Extraction\n",
    "Extract features from text and images (no videos/audio in your dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25e622a9-4ce4-451f-a51c-3c75b6c1208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')\n",
    "clip_model = CLIPModel.from_pretrained('openai/clip-vit-base-patch32').to(device)\n",
    "\n",
    "def extract_text_features(text):\n",
    "    inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "def extract_image_features(image_path):\n",
    "    try:\n",
    "        if image_path.startswith('http'):  # If URL\n",
    "            image = Image.open(requests.get(image_path, stream=True).raw).convert('RGB')\n",
    "        else:  # Local path\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        inputs = clip_processor(images=image, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            features = clip_model.get_image_features(**inputs)\n",
    "        return features.squeeze().cpu().numpy()\n",
    "    except:\n",
    "        return np.zeros(512)  # CLIP image feature dim\n",
    "\n",
    "# Apply to dataset\n",
    "df['text'] = df['caption'] + ' ' + df['hashtags']\n",
    "df['text_features'] = df['text'].apply(extract_text_features)\n",
    "df['image_features'] = df['image_path'].apply(extract_image_features)\n",
    "\n",
    "# Combine features (text + image only)\n",
    "def combine_features(row):\n",
    "    text_feat = row['text_features']\n",
    "    img_feat = row['image_features']\n",
    "    return np.concatenate([text_feat, img_feat])\n",
    "\n",
    "df['combined_features'] = df.apply(combine_features, axis=1)\n",
    "X = np.array(df['combined_features'].tolist())\n",
    "y = df['performance'].astype('category').cat.codes  # Encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369378c2-0c10-45b6-a173-034c5499da0a",
   "metadata": {},
   "source": [
    "## Step 3: Train Model\n",
    "Train a classifier on the combined features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1789955d-20e0-43b8-aafe-9cf7b2559d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.10      0.10        10\n",
      "           1       0.90      0.90      0.90        90\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.50      0.50      0.50       100\n",
      "weighted avg       0.82      0.82      0.82       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['performance_predictor.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(model, 'performance_predictor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c9d35-7ba3-49ea-970f-10814cce2f67",
   "metadata": {},
   "source": [
    "## Step 4: Prediction Function\n",
    "Function to predict for new content (image path, caption, hashtags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9188eb36-dcf3-4e69-ad7c-dc28d515e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium\n"
     ]
    }
   ],
   "source": [
    "def predict_performance(caption, hashtags, image_path=None):\n",
    "    text = caption + ' ' + hashtags\n",
    "    text_feat = extract_text_features(text)\n",
    "    img_feat = extract_image_features(image_path) if image_path else np.zeros(512)\n",
    "    features = np.concatenate([text_feat, img_feat]).reshape(1, -1)\n",
    "    pred = model.predict(features)[0]\n",
    "    labels = ['Low', 'Medium', 'High']\n",
    "    return labels[pred]\n",
    "\n",
    "# Example\n",
    "print(predict_performance('Amazing sunset!', '#sunset #photography', 'path/to/image.jpg'))  # Replace with actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ee8eb-dda9-4a45-9539-52f9561e9825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f8867-61c2-432b-b3e6-c14bfa1c21e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e5af5-066e-4a48-8d83-83e34688c8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0a186-c545-4605-9db5-e067d376ee2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02b148-8ff8-4bc7-8728-614b5be1a7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b321335-adcc-4920-8a9f-99952d20b25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71cad0-d158-4b92-8d6b-a662fd8efc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10253fb2-d1a1-4a30-857d-a31e7a0c4749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89c4c1-727e-4ca5-a41f-43abe62f6a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236322e-f4d9-4715-bf19-3219e4db3b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6557e0b4-b92f-4423-a203-dda44c85cd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8716b-aaef-496f-b5e7-979c96104b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
